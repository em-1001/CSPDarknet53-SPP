{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EQJpQ8AQHhXo",
        "outputId": "440cb90b-d334-4205-e1f8-897a630fef07"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "F_oU9hY7Hmuo"
      },
      "outputs": [],
      "source": [
        "!mkdir -p ~/.kaggle\n",
        "!cp kaggle.json ~/.kaggle/\n",
        "!chmod 600 ~/.kaggle/kaggle.json"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UrQbPFI-Hqk9",
        "outputId": "d963d9fe-a699-4a0c-bf39-6bbc5e1e05f9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading pascal-voc-dataset-used-in-yolov3-video.zip to /content\n",
            "100% 4.30G/4.31G [03:40<00:00, 21.3MB/s]\n",
            "100% 4.31G/4.31G [03:40<00:00, 21.0MB/s]\n"
          ]
        }
      ],
      "source": [
        "!kaggle datasets download -d aladdinpersson/pascal-voc-dataset-used-in-yolov3-video"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "8zCYxb9aHq5d"
      },
      "outputs": [],
      "source": [
        "!unzip  -qq /content/pascal-voc-dataset-used-in-yolov3-video.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bj2FJ-4OaO6u"
      },
      "outputs": [],
      "source": [
        "# https://wikidocs.net/181720\n",
        "# https://github.com/RichardMinsooGo-ML/TF2.0-Yolov3-Yolov4-image/blob/main/yolo_core/models.py"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# YOLOv4 model\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import math\n",
        "\n",
        "class DarknetConv2D(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, kernel_size=3, stride=1, downsample=False, bn_act=True, act=\"mish\"):\n",
        "        super().__init__()\n",
        "\n",
        "        if downsample:\n",
        "            kernel_size = 3\n",
        "            stride = 2\n",
        "            padding = \"valid\"\n",
        "\n",
        "        else:\n",
        "            stride = 1\n",
        "            padding = \"same\"\n",
        "\n",
        "        self.conv = nn.Conv2d(\n",
        "            in_channels=in_channels, out_channels=out_channels,\n",
        "            kernel_size=kernel_size, stride=stride, padding=padding,\n",
        "            bias=not bn_act\n",
        "        )\n",
        "\n",
        "        self.downsample = downsample\n",
        "        self.bn = nn.BatchNorm2d(out_channels)\n",
        "        self.mish = nn.Mish()\n",
        "        self.leaky = nn.LeakyReLU(0.1)\n",
        "        self.use_bn_act = bn_act\n",
        "        self.act = act\n",
        "\n",
        "    def forward(self, x):\n",
        "        if self.downsample:\n",
        "            x = torch.nn.functional.pad(x, (1, 0, 1, 0))\n",
        "        if self.use_bn_act:\n",
        "            if self.act == \"mish\":\n",
        "                return self.mish(self.bn(self.conv(x)))\n",
        "            elif self.act == \"leaky\":\n",
        "                return self.leaky(self.bn(self.conv(x)))\n",
        "        else:\n",
        "            return self.conv(x)\n",
        "\n",
        "\n",
        "\n",
        "class CSPResBlock(nn.Module):\n",
        "    def __init__(self, in_channels, num_repeats=1):\n",
        "        super().__init__()\n",
        "\n",
        "        self.split1x1 = DarknetConv2D(in_channels=in_channels, out_channels=in_channels//2, kernel_size=1)\n",
        "        self.res1x1 = DarknetConv2D(in_channels=in_channels//2, out_channels=in_channels//2, kernel_size=1)\n",
        "        self.concat1x1 = DarknetConv2D(in_channels=in_channels, out_channels=in_channels, kernel_size=1)\n",
        "        self.num_repeats = num_repeats\n",
        "\n",
        "        self.DenseBlock = nn.ModuleList()\n",
        "        for i in range(num_repeats):\n",
        "            DenseLayer = nn.ModuleList()\n",
        "            DenseLayer.append(DarknetConv2D(in_channels=in_channels//2, out_channels=in_channels//2, kernel_size=1))\n",
        "            DenseLayer.append(DarknetConv2D(in_channels=in_channels//2, out_channels=in_channels//2, kernel_size=3))\n",
        "            self.DenseBlock.append(DenseLayer)\n",
        "\n",
        "    def forward(self, x):\n",
        "        route = self.split1x1(x)\n",
        "        x = self.split1x1(x)\n",
        "\n",
        "        for module in self.DenseBlock:\n",
        "            h = x\n",
        "            for res in module:\n",
        "                h = res(h)\n",
        "            x = x + h\n",
        "\n",
        "        x = self.res1x1(x)\n",
        "        x = torch.cat([x, route], dim=1)\n",
        "        x = self.concat1x1(x)\n",
        "\n",
        "        return x\n",
        "\n",
        "\n",
        "\n",
        "class SPP(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "        self.maxpool5 = nn.MaxPool2d(kernel_size=5, stride=1, padding=2)\n",
        "        self.maxpool9 = nn.MaxPool2d(kernel_size=9, stride=1, padding=4)\n",
        "        self.maxpool13 = nn.MaxPool2d(kernel_size=13, stride=1, padding=6)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = torch.cat([x,\n",
        "                       self.maxpool5(x),\n",
        "                       self.maxpool9(x),\n",
        "                       self.maxpool13(x)], dim=1)\n",
        "\n",
        "        return x\n",
        "\n",
        "\n",
        "\n",
        "class ScalePrediction(nn.Module):\n",
        "    def __init__(self, in_channels, num_classes):\n",
        "        super().__init__()\n",
        "\n",
        "        self.conv = DarknetConv2D(in_channels=in_channels, out_channels=in_channels*2, kernel_size=3, act=\"leaky\")\n",
        "        self.ScalePred = DarknetConv2D(in_channels=in_channels*2, out_channels=3*(num_classes+5), kernel_size=1, bn_act=False, act=\"leaky\")\n",
        "        self.num_classes = num_classes\n",
        "\n",
        "    def forward(self, x):\n",
        "        return(\n",
        "            self.ScalePred(self.conv(x))\n",
        "            # x = [batch_num, 3*(num_classes + 5), N, N\n",
        "            .reshape(x.shape[0], 3, self.num_classes + 5, x.shape[2], x.shape[3])\n",
        "            .permute(0, 1, 3, 4, 2)\n",
        "            # output = [B x 3 x N x N x 5+num_classes]\n",
        "        )\n",
        "\n",
        "\n",
        "\n",
        "class CSPDarknet53(nn.Module):\n",
        "    def __init__(self, in_channels):\n",
        "        super().__init__()\n",
        "\n",
        "        self.in_channels = in_channels\n",
        "\n",
        "        self.layers = nn.ModuleList([\n",
        "            DarknetConv2D(in_channels=in_channels, out_channels=32, kernel_size=3),\n",
        "            DarknetConv2D(in_channels=32, out_channels=64, kernel_size=3, downsample=True),\n",
        "            CSPResBlock(in_channels=64, num_repeats=1),\n",
        "            DarknetConv2D(in_channels=64, out_channels=128, kernel_size=3, downsample=True),\n",
        "            CSPResBlock(in_channels=128, num_repeats=2),\n",
        "            DarknetConv2D(in_channels=128, out_channels=256, kernel_size=3, downsample=True),\n",
        "            CSPResBlock(in_channels=256, num_repeats=8), # Route_1\n",
        "            DarknetConv2D(in_channels=256, out_channels=512, kernel_size=3, downsample=True),\n",
        "            CSPResBlock(in_channels=512, num_repeats=8), # Route_2\n",
        "            DarknetConv2D(in_channels=512, out_channels=1024, kernel_size=3, downsample=True),\n",
        "            CSPResBlock(in_channels=1024, num_repeats=4),\n",
        "            DarknetConv2D(in_channels=1024, out_channels=512, kernel_size=1, act=\"leaky\"),\n",
        "            DarknetConv2D(in_channels=512, out_channels=1024, kernel_size=3, act=\"leaky\"),\n",
        "            DarknetConv2D(in_channels=1024, out_channels=512, kernel_size=1, act=\"leaky\"),\n",
        "            SPP(),\n",
        "            DarknetConv2D(in_channels=2048, out_channels=512, kernel_size=1, act=\"leaky\"),\n",
        "            DarknetConv2D(in_channels=512, out_channels=1024, kernel_size=3, act=\"leaky\"),\n",
        "            DarknetConv2D(in_channels=1024, out_channels=512, kernel_size=1, act=\"leaky\") # output\n",
        "        ])\n",
        "\n",
        "    def forward(self, x):\n",
        "        route = []\n",
        "\n",
        "        for layer in self.layers:\n",
        "            x = layer(x)\n",
        "\n",
        "            if isinstance(layer, CSPResBlock) and layer.num_repeats == 8:\n",
        "                route.append(x)\n",
        "\n",
        "        route.append(x)\n",
        "\n",
        "        return tuple(route)\n",
        "\n",
        "\n",
        "\n",
        "class Conv5(nn.Module):\n",
        "    def __init__(self, in_channels, up=True):\n",
        "        super().__init__()\n",
        "\n",
        "        self.in_channels = in_channels\n",
        "        self.up = up\n",
        "        self.conv1x1 = DarknetConv2D(in_channels=in_channels, out_channels=in_channels//2, kernel_size=1, act=\"leaky\")\n",
        "        self.conv3x3 = DarknetConv2D(in_channels=in_channels//2, out_channels=in_channels, kernel_size=3, act=\"leaky\")\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv1x1(x)\n",
        "        x = self.conv3x3(x)\n",
        "        x = self.conv1x1(x)\n",
        "        x = self.conv3x3(x)\n",
        "        x = self.conv1x1(x)\n",
        "\n",
        "        return x\n",
        "\n",
        "\n",
        "\n",
        "class YOLOv4(nn.Module):\n",
        "    def __init__(self, in_channels=3, num_classes=80):\n",
        "        super().__init__()\n",
        "\n",
        "        self.in_channels = in_channels\n",
        "        self.num_classes = num_classes\n",
        "        self.CSPDarknet53 = CSPDarknet53(in_channels)\n",
        "        self.route2conv = DarknetConv2D(in_channels=512, out_channels=256, kernel_size=1, act=\"leaky\")\n",
        "        self.route1conv = DarknetConv2D(in_channels=256, out_channels=128, kernel_size=1, act=\"leaky\")\n",
        "\n",
        "        self.layers = nn.ModuleList([\n",
        "            DarknetConv2D(in_channels=512, out_channels=256, kernel_size=1, act=\"leaky\"),\n",
        "            nn.Upsample(scale_factor=2, mode='nearest'),\n",
        "            Conv5(in_channels=512, up=True), # after concat\n",
        "            DarknetConv2D(in_channels=256, out_channels=128, kernel_size=1, act=\"leaky\"),\n",
        "            nn.Upsample(scale_factor=2, mode='nearest'),\n",
        "            Conv5(in_channels=256, up=True), # after concat\n",
        "            ScalePrediction(in_channels=128, num_classes=num_classes), # sbbox 52x52\n",
        "            DarknetConv2D(in_channels=128, out_channels=256, kernel_size=3, downsample=True, act=\"leaky\"),\n",
        "            Conv5(in_channels=512, up=False),\n",
        "            ScalePrediction(in_channels=256, num_classes=num_classes), # mbbox 26x26\n",
        "            DarknetConv2D(in_channels=256, out_channels=512, kernel_size=3, downsample=True, act=\"leaky\"),\n",
        "            Conv5(in_channels=1024, up=False),\n",
        "            ScalePrediction(in_channels=512, num_classes=num_classes)  # lbbox 13x13\n",
        "        ])\n",
        "\n",
        "    def forward(self, x):\n",
        "        outputs = []\n",
        "        Route = []\n",
        "        OutputRoute = []\n",
        "        route1, route2, CSPout = self.CSPDarknet53(x)\n",
        "\n",
        "        OutputRoute.append(CSPout)\n",
        "\n",
        "        route2 = self.route2conv(route2)\n",
        "        route1 = self.route1conv(route1)\n",
        "        Route.append(route1)\n",
        "        Route.append(route2)\n",
        "\n",
        "\n",
        "        x = CSPout\n",
        "        for layer in self.layers:\n",
        "            if isinstance(layer, ScalePrediction):\n",
        "                outputs.append(layer(x))\n",
        "                continue # Since this is the output of each scale, it must skip x = ScalePrediction(x).\n",
        "\n",
        "            x = layer(x)\n",
        "\n",
        "            if isinstance(layer, nn.Upsample):\n",
        "                x = torch.cat([Route[-1], x], dim=1)\n",
        "                Route.pop()\n",
        "\n",
        "            if isinstance(layer, Conv5) and layer.in_channels == 512 and layer.up == True:\n",
        "                OutputRoute.append(x)\n",
        "\n",
        "            if isinstance(layer, DarknetConv2D) and layer.downsample == True:\n",
        "                x = torch.cat([x, OutputRoute[-1]], dim=1)\n",
        "                OutputRoute.pop()\n",
        "\n",
        "        outputs[0], outputs[1], outputs[2] = outputs[2], outputs[1], outputs[0]\n",
        "        return outputs\n",
        "\n",
        "        '''\n",
        "        torch.Size([1, 13, 13, 255])\n",
        "        torch.Size([1, 26, 26, 255])\n",
        "        torch.Size([1, 52, 52, 255])\n",
        "        '''"
      ],
      "metadata": {
        "id": "rAIZ6FxO_am_"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# model test\n",
        "# import config\n",
        "num_classes = 20\n",
        "IMAGE_SIZE = 416\n",
        "model = YOLOv4(num_classes=num_classes)\n",
        "\n",
        "x = torch.randn((2, 3, IMAGE_SIZE, IMAGE_SIZE))\n",
        "out = model(x)\n",
        "\n",
        "assert out[0].shape == (2, 3, IMAGE_SIZE//32, IMAGE_SIZE//32, num_classes + 5)\n",
        "assert out[1].shape == (2, 3, IMAGE_SIZE//16, IMAGE_SIZE//16, num_classes + 5)\n",
        "assert out[2].shape == (2, 3, IMAGE_SIZE//8, IMAGE_SIZE//8, num_classes + 5)\n",
        "print(\"Success!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LRalADpNDRh1",
        "outputId": "06199e2d-9eac-4f46-b77d-afc6f3229cdf"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Success!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 889
        },
        "id": "9YhqQQzPmxby",
        "outputId": "5456f998-efe2-43f2-a767-579a3838a6cd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/albumentations/imgaug/transforms.py:346: FutureWarning: This IAAAffine is deprecated. Please use Affine instead\n",
            "  warnings.warn(\"This IAAAffine is deprecated. Please use Affine instead\", FutureWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[(0.3, 0.23), (0.41, 0.52), (0.99, 0.87)], [(0.07, 0.16), (0.16, 0.11), (0.15, 0.31)], [(0.02, 0.03), (0.04, 0.07), (0.08, 0.06)]]\n",
            "0.001\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 518/518 [06:20<00:00,  1.36it/s, loss=16.1]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=> Saving checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 518/518 [06:12<00:00,  1.39it/s, loss=12.9]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=> Saving checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 518/518 [06:12<00:00,  1.39it/s, loss=12]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=> Saving checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 518/518 [06:13<00:00,  1.39it/s, loss=11.3]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=> Saving checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 518/518 [06:14<00:00,  1.38it/s, loss=10.8]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=> Saving checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 518/518 [06:15<00:00,  1.38it/s, loss=10.3]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=> Saving checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 518/518 [06:15<00:00,  1.38it/s, loss=10]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=> Saving checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 518/518 [06:16<00:00,  1.38it/s, loss=9.73]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=> Saving checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 518/518 [06:16<00:00,  1.38it/s, loss=9.43]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=> Saving checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 518/518 [06:16<00:00,  1.38it/s, loss=9.19]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=> Saving checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 155/155 [04:22<00:00,  1.70s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MAP: 0.014559321105480194\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  3%|▎         | 13/518 [00:11<07:09,  1.18it/s, loss=9.85]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-7aa1c9b24312>\u001b[0m in \u001b[0;36m<cell line: 117>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    116\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 118\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-2-7aa1c9b24312>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     83\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m200\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 85\u001b[0;31m         \u001b[0mtrain_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscaler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscaled_anchors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbox_loss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"MSE\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     86\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSAVE_MODEL\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-2-7aa1c9b24312>\u001b[0m in \u001b[0;36mtrain_fn\u001b[0;34m(train_loader, model, optimizer, loss_fn, scaler, scaled_anchors, box_loss)\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m         \u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscale\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m         \u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m         \u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/cuda/amp/grad_scaler.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, optimizer, *args, **kwargs)\u001b[0m\n\u001b[1;32m    414\u001b[0m         ), \"No inf checks were recorded for this optimizer.\"\n\u001b[1;32m    415\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 416\u001b[0;31m         \u001b[0mretval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_opt_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    417\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    418\u001b[0m         \u001b[0moptimizer_state\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"stage\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mOptState\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSTEPPED\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/cuda/amp/grad_scaler.py\u001b[0m in \u001b[0;36m_maybe_opt_step\u001b[0;34m(self, optimizer, optimizer_state, *args, **kwargs)\u001b[0m\n\u001b[1;32m    312\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_maybe_opt_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m         \u001b[0mretval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 314\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0moptimizer_state\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"found_inf_per_device\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    315\u001b[0m             \u001b[0mretval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    316\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mretval\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/cuda/amp/grad_scaler.py\u001b[0m in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    312\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_maybe_opt_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m         \u001b[0mretval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 314\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0moptimizer_state\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"found_inf_per_device\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    315\u001b[0m             \u001b[0mretval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    316\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mretval\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "import config\n",
        "import torch\n",
        "import torch.optim as optim\n",
        "\n",
        "# from yolov4 import YOLOv4\n",
        "from tqdm import tqdm\n",
        "from utils import (\n",
        "    mean_average_precision,\n",
        "    non_max_suppression,\n",
        "    cells_to_bboxes,\n",
        "    get_evaluation_bboxes,\n",
        "    save_checkpoint,\n",
        "    load_checkpoint,\n",
        "    check_class_accuracy,\n",
        "    get_loaders,\n",
        "    plot_couple_examples,\n",
        "    plot_image\n",
        ")\n",
        "from loss import YoloLoss\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "torch.backends.cudnn.benchmark = True\n",
        "\n",
        "\n",
        "print(config.ANCHORS)\n",
        "print(config.LEARNING_RATE)\n",
        "\n",
        "\n",
        "def train_fn(train_loader, model, optimizer, loss_fn, scaler, scaled_anchors, box_loss=\"MSE\"):\n",
        "    loop = tqdm(train_loader, leave=True)\n",
        "    losses = []\n",
        "    for batch_idx, (x, y) in enumerate(loop):\n",
        "        x = x.to(config.DEVICE)\n",
        "        y0, y1, y2 = (\n",
        "            y[0].to(config.DEVICE),\n",
        "            y[1].to(config.DEVICE),\n",
        "            y[2].to(config.DEVICE),\n",
        "        )\n",
        "\n",
        "        with torch.cuda.amp.autocast():\n",
        "            out = model(x)\n",
        "            loss = (\n",
        "                loss_fn(out[0], y0, scaled_anchors[0], box_loss=box_loss)\n",
        "                + loss_fn(out[1], y1, scaled_anchors[1], box_loss=box_loss)\n",
        "                + loss_fn(out[2], y2, scaled_anchors[2], box_loss=box_loss)\n",
        "            )\n",
        "\n",
        "        losses.append(loss.item())\n",
        "        optimizer.zero_grad()\n",
        "        scaler.scale(loss).backward()\n",
        "        scaler.step(optimizer)\n",
        "        scaler.update()\n",
        "\n",
        "        # update progress bar\n",
        "        mean_loss = sum(losses) / len(losses)\n",
        "        loop.set_postfix(loss=mean_loss)\n",
        "\n",
        "\n",
        "\n",
        "def main():\n",
        "    model = YOLOv4(num_classes=config.NUM_CLASSES).to(config.DEVICE)\n",
        "    # model = YOLOv4(backbone=CSPDarknet53(pretrained=True)).to(config.DEVICE)\n",
        "    optimizer = optim.Adam(\n",
        "        model.parameters(), lr=config.LEARNING_RATE, weight_decay=config.WEIGHT_DECAY\n",
        "    )\n",
        "    loss_fn = YoloLoss()\n",
        "    scaler = torch.cuda.amp.GradScaler()\n",
        "\n",
        "    train_loader, test_loader, train_eval_loader = get_loaders(\n",
        "        train_csv_path=config.DATASET + \"/train.csv\", test_csv_path=config.DATASET + \"/test.csv\"\n",
        "    )\n",
        "\n",
        "    if False: # config.LOAD_MODEL\n",
        "        load_checkpoint(\n",
        "            config.CHECKPOINT_FILE, model, optimizer, config.LEARNING_RATE\n",
        "        ) # config.CHECKPOINT_FILE\n",
        "\n",
        "    scaled_anchors = (\n",
        "        torch.tensor(config.ANCHORS)\n",
        "        * torch.tensor(config.S).unsqueeze(1).unsqueeze(1).repeat(1, 3, 2)\n",
        "    ).to(config.DEVICE)\n",
        "\n",
        "    for epoch in range(200):\n",
        "        train_fn(train_loader, model, optimizer, loss_fn, scaler, scaled_anchors, box_loss=\"MSE\")\n",
        "\n",
        "        if config.SAVE_MODEL:\n",
        "            save_checkpoint(model, optimizer, filename=f\"/content/drive/MyDrive/yolov3/checkpoint.pth.tar\")\n",
        "\n",
        "        #print(f\"Currently epoch {epoch}\")\n",
        "        #print(\"On Train Eval loader:\")\n",
        "        #print(\"On Train loader:\")\n",
        "        #check_class_accuracy(model, train_loader, threshold=config.CONF_THRESHOLD)\n",
        "\n",
        "        if epoch > 0 and (epoch+1) % 10 == 0:\n",
        "            #plot_couple_examples(model, test_loader, 0.2, 0.45, scaled_anchors , iou_mode=\"IoU\")\n",
        "            # check_class_accuracy(model, test_loader, threshold=config.CONF_THRESHOLD)\n",
        "            pred_boxes, true_boxes = get_evaluation_bboxes(\n",
        "                test_loader,\n",
        "                model,\n",
        "                iou_threshold=0.45,\n",
        "                anchors=config.ANCHORS,\n",
        "                threshold=0.5,\n",
        "                iou_mode = \"IoU\"\n",
        "            )\n",
        "            mapval = mean_average_precision(\n",
        "                pred_boxes,\n",
        "                true_boxes,\n",
        "                iou_threshold=config.MAP_IOU_THRESH,\n",
        "                box_format=\"midpoint\",\n",
        "                num_classes=config.NUM_CLASSES,\n",
        "            )\n",
        "            print(f\"MAP: {mapval.item()}\")\n",
        "            model.train()\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "v_6xSIYaU5k4"
      },
      "outputs": [],
      "source": [
        "model = YOLOv4(num_classes=config.NUM_CLASSES).to(config.DEVICE)\n",
        "optimizer = optim.Adam(\n",
        "    model.parameters(), lr=config.LEARNING_RATE, weight_decay=config.WEIGHT_DECAY\n",
        ")\n",
        "loss_fn = YoloLoss()\n",
        "scaler = torch.cuda.amp.GradScaler()\n",
        "\n",
        "train_loader, test_loader, train_eval_loader = get_loaders(\n",
        "    train_csv_path=config.DATASET + \"/train.csv\", test_csv_path=config.DATASET + \"/test.csv\"\n",
        ")\n",
        "\n",
        "if True: # config.LOAD_MODEL\n",
        "    load_checkpoint(\n",
        "        config.CHECKPOINT_FILE, model, optimizer, config.LEARNING_RATE\n",
        "    )\n",
        "\n",
        "scaled_anchors = (\n",
        "    torch.tensor(config.ANCHORS)\n",
        "    * torch.tensor(config.S).unsqueeze(1).unsqueeze(1).repeat(1, 3, 2)\n",
        ").to(config.DEVICE)\n",
        "\n",
        "plot_couple_examples(model, test_loader, 0.2, 0.45, scaled_anchors , iou_mode=\"IoU\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E40oeRmk8SRV",
        "outputId": "342f663d-6954-41ee-c061-ea7359077521"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Input shape: torch.Size([1, 3, 32, 32])\n",
            "Output1 shape: torch.Size([1, 64, 16, 16])\n",
            "Output2 shape: torch.Size([1, 64, 16, 16])\n",
            "SPP Input shape: torch.Size([1, 512, 32, 32])\n",
            "SPP Output shape: torch.Size([1, 2048, 32, 32])\n",
            "ScalePrediction Input shape: torch.Size([1, 512, 52, 52])\n",
            "ScalePrediction Output shape: torch.Size([1, 255, 52, 52])\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "\n",
        "# 예제 입력 데이터 생성 (배치 크기, 채널 수, 높이, 너비)\n",
        "batch_size, in_channels, height, width = 1, 3, 32, 32\n",
        "input_data = torch.randn(batch_size, in_channels, height, width)\n",
        "\n",
        "# DarknetConv2D 레이어 생성\n",
        "darknet_conv = DarknetConv2D(in_channels=3, out_channels=64, downsample=True, bn_act=True, act=\"mish\")\n",
        "res = CSPResBlock(in_channels=64, num_repeats=1)\n",
        "\n",
        "# 결과 출력\n",
        "output_data1 = darknet_conv(input_data)\n",
        "output_data2 = res(output_data1)\n",
        "print(\"Input shape:\", input_data.shape)\n",
        "print(\"Output1 shape:\", output_data1.shape)\n",
        "print(\"Output2 shape:\", output_data2.shape)\n",
        "\n",
        "\n",
        "batch_size, in_channels, height, width = 1, 512, 32, 32\n",
        "input_data = torch.randn(batch_size, in_channels, height, width)\n",
        "spp = SPP()\n",
        "output_data = spp(input_data)\n",
        "\n",
        "print(\"SPP Input shape:\", input_data.shape)\n",
        "print(\"SPP Output shape:\", output_data.shape)\n",
        "\n",
        "\n",
        "batch_size, in_channels, height, width = 1, 512, 52, 52\n",
        "input_data = torch.randn(batch_size, in_channels, height, width)\n",
        "sp = ScalePrediction(in_channels=512, num_classes=80)\n",
        "output_data = sp(input_data)\n",
        "\n",
        "print(\"ScalePrediction Input shape:\", input_data.shape)\n",
        "print(\"ScalePrediction Output shape:\", output_data.shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oiSAiplEn89E",
        "outputId": "4091a33a-93f2-4eb1-c7f6-0bfacdf4c430"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CSPDarknet53 Route1: torch.Size([2, 256, 52, 52])\n",
            "CSPDarknet53 Route2: torch.Size([2, 512, 26, 26])\n",
            "CSPDarknet53 Output: torch.Size([2, 512, 13, 13])\n"
          ]
        }
      ],
      "source": [
        "batch_size, in_channels, height, width = 2, 3, 416, 416\n",
        "input_data = torch.randn(batch_size, in_channels, height, width)\n",
        "darknet = CSPDarknet53(in_channels=3)\n",
        "route1, route2, ouput = darknet(input_data)\n",
        "\n",
        "print(\"CSPDarknet53 Route1:\", route1.shape)\n",
        "print(\"CSPDarknet53 Route2:\", route2.shape)\n",
        "print(\"CSPDarknet53 Output:\", ouput.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "n8-yyZzq2jm5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2936d4d3-65c1-4336-907f-0594271627de"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.026143790849673203, 0.034858387799564274, 0.04139433551198257, 0.0784313725490196, 0.08714596949891068, 0.06100217864923747, 0.0784313725490196, 0.16339869281045752, 0.1655773420479303, 0.11982570806100218, 0.1568627450980392, 0.31808278867102396, 0.3093681917211329, 0.23965141612200436, 0.41830065359477125, 0.5294117647058824, 1.0, 0.8736383442265795]\n"
          ]
        }
      ],
      "source": [
        "anchor_values = [12, 16, 19, 36, 40, 28, 36, 75, 76, 55, 72, 146, 142, 110, 192, 243, 459, 401]\n",
        "\n",
        "# 최댓값 계산\n",
        "max_value = max(anchor_values)\n",
        "\n",
        "# 각 값을 최댓값으로 나누어 정규화\n",
        "normalized_anchors = [value / max_value for value in anchor_values]\n",
        "\n",
        "print(normalized_anchors)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# model test\n",
        "# import config\n",
        "num_classes = 20\n",
        "IMAGE_SIZE = 416\n",
        "model = YOLOv4(backbone=CSPDarknet53(pretrained=True))\n",
        "\n",
        "x = torch.randn((2, 3, IMAGE_SIZE, IMAGE_SIZE))\n",
        "out = model(x)\n",
        "\n",
        "assert out[0].shape == (2, 3, IMAGE_SIZE//32, IMAGE_SIZE//32, num_classes + 5)\n",
        "assert out[1].shape == (2, 3, IMAGE_SIZE//16, IMAGE_SIZE//16, num_classes + 5)\n",
        "assert out[2].shape == (2, 3, IMAGE_SIZE//8, IMAGE_SIZE//8, num_classes + 5)\n",
        "print(\"Success!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rfnd-XXTI4FB",
        "outputId": "304586bc-7971-48ed-98b8-6fa45b4c7d25"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "num_params :  63012949\n",
            "Success!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "4dt-jNUUJOVD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "# import wget\n",
        "import os\n",
        "import torch.nn as nn\n",
        "\n",
        "import numpy as np\n",
        "import torch.nn.functional as F\n",
        "\n",
        "\n",
        "class ResidualBlock(nn.Module):\n",
        "    def __init__(self, in_channel, hidden_channel=None):\n",
        "        if hidden_channel is None:\n",
        "            hidden_channel = in_channel\n",
        "        super().__init__()\n",
        "        self.features = nn.Sequential(nn.Conv2d(in_channel, hidden_channel, 1, stride=1, padding=0, bias=False),\n",
        "                                      nn.BatchNorm2d(hidden_channel),\n",
        "                                      Mish(),\n",
        "                                      nn.Conv2d(hidden_channel, in_channel, 3, stride=1, padding=1, bias=False),\n",
        "                                      nn.BatchNorm2d(in_channel),\n",
        "                                      Mish(),\n",
        "                                      )\n",
        "\n",
        "    def forward(self, x):\n",
        "        residual = x\n",
        "        x = self.features(x)\n",
        "        x += residual\n",
        "        return x\n",
        "\n",
        "\n",
        "class Mish(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Mish, self).__init__()\n",
        "\n",
        "    def forward(self, x):\n",
        "        return x * torch.tanh(F.softplus(x))\n",
        "\n",
        "\n",
        "class CSPBlock(nn.Module):\n",
        "    def __init__(self, in_channel, is_first=False, num_blocks=1):\n",
        "        super().__init__()\n",
        "        self.part1_conv = nn.Sequential(nn.Conv2d(in_channel, in_channel//2, 1, stride=1, padding=0, bias=False),\n",
        "                                        nn.BatchNorm2d(in_channel//2),\n",
        "                                        Mish())\n",
        "        self.part2_conv = nn.Sequential(nn.Conv2d(in_channel, in_channel//2, 1, stride=1, padding=0, bias=False),\n",
        "                                        nn.BatchNorm2d(in_channel//2),\n",
        "                                        Mish())\n",
        "        self.features = nn.Sequential(*[ResidualBlock(in_channel=in_channel//2) for _ in range(num_blocks)])\n",
        "        self.transition1_conv = nn.Sequential(nn.Conv2d(in_channel//2, in_channel//2, 1, stride=1, padding=0, bias=False),\n",
        "                                              nn.BatchNorm2d(in_channel//2),\n",
        "                                              Mish())\n",
        "        self.transition2_conv = nn.Sequential(nn.Conv2d(in_channel, in_channel, 1, stride=1, padding=0, bias=False),\n",
        "                                              nn.BatchNorm2d(in_channel),\n",
        "                                              Mish())\n",
        "        if is_first:\n",
        "            self.part1_conv = nn.Sequential(nn.Conv2d(in_channel, in_channel, 1, stride=1, padding=0, bias=False),\n",
        "                                            nn.BatchNorm2d(in_channel),\n",
        "                                            Mish())\n",
        "            self.part2_conv = nn.Sequential(nn.Conv2d(in_channel, in_channel, 1, stride=1, padding=0, bias=False),\n",
        "                                            nn.BatchNorm2d(in_channel),\n",
        "                                            Mish())\n",
        "            self.features = nn.Sequential(*[ResidualBlock(in_channel=in_channel,\n",
        "                                                          hidden_channel=in_channel//2) for _ in range(num_blocks)])\n",
        "            self.transition1_conv = nn.Sequential(nn.Conv2d(in_channel, in_channel, 1, stride=1, padding=0, bias=False),\n",
        "                                                  nn.BatchNorm2d(in_channel),\n",
        "                                                  Mish())\n",
        "            self.transition2_conv = nn.Sequential(nn.Conv2d(2 * in_channel, in_channel, 1, stride=1, padding=0, bias=False),\n",
        "                                                  nn.BatchNorm2d(in_channel),\n",
        "                                                  Mish())\n",
        "\n",
        "    def forward(self, x):\n",
        "        # split features\n",
        "        part1 = self.part1_conv(x)\n",
        "        part2 = self.part2_conv(x)\n",
        "\n",
        "        # residual\n",
        "        residual = part2\n",
        "        part2 = self.features(part2)\n",
        "        part2 += residual\n",
        "        part2 = self.transition1_conv(part2)\n",
        "\n",
        "        x = self.transition2_conv(torch.cat([part1, part2], dim=1))\n",
        "        return x\n",
        "\n",
        "\n",
        "class CSPDarknet53(nn.Module):\n",
        "    def __init__(self, num_classes=20, pretrained=False):\n",
        "        super().__init__()\n",
        "\n",
        "        self.num_classes = num_classes\n",
        "        self.features1 = nn.Sequential(\n",
        "            nn.Conv2d(3, 32, 3, stride=1, padding=1, bias=False),\n",
        "            nn.BatchNorm2d(32),\n",
        "            Mish(),\n",
        "            nn.Conv2d(32, 64, 3, stride=2, padding=1, bias=False),\n",
        "            nn.BatchNorm2d(64),\n",
        "            Mish(),\n",
        "            CSPBlock(64, is_first=True, num_blocks=1),\n",
        "            nn.Conv2d(64, 128, 3, stride=2, padding=1, bias=False),\n",
        "            nn.BatchNorm2d(128),\n",
        "            Mish(),\n",
        "            CSPBlock(128, num_blocks=2),\n",
        "            nn.Conv2d(128, 256, 3, stride=2, padding=1, bias=False),\n",
        "            nn.BatchNorm2d(256),\n",
        "            Mish(),\n",
        "            CSPBlock(256, num_blocks=8),\n",
        "        )\n",
        "\n",
        "        self.features2 = nn.Sequential(\n",
        "            nn.Conv2d(256, 512, 3, stride=2, padding=1, bias=False),\n",
        "            nn.BatchNorm2d(512),\n",
        "            Mish(),\n",
        "            CSPBlock(512, num_blocks=8),\n",
        "        )\n",
        "\n",
        "        self.features3 = nn.Sequential(\n",
        "            nn.Conv2d(512, 1024, 3, stride=2, padding=1, bias=False),\n",
        "            nn.BatchNorm2d(1024),\n",
        "            Mish(),\n",
        "            CSPBlock(1024, num_blocks=4),\n",
        "        )\n",
        "\n",
        "        self.gap = nn.AdaptiveAvgPool2d((1, 1))\n",
        "        self.fc = nn.Linear(1024, self.num_classes)\n",
        "        self.init_layer()\n",
        "\n",
        "\n",
        "    def count_parameters(self):\n",
        "        return sum(p.numel() for p in self.parameters())\n",
        "\n",
        "    def init_layer(self):\n",
        "        for layer in self.children():\n",
        "            if isinstance(layer, nn.Conv2d):\n",
        "                nn.init.xavier_uniform_(layer.weight)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.features1(x)\n",
        "        x = self.features2(x)\n",
        "        x = self.features3(x)\n",
        "        x = self.gap(x)\n",
        "        x = x.view(-1, 1024)\n",
        "        x = self.fc(x)\n",
        "        return x\n",
        "\n",
        "    def load_darknet_weights(self, weights_path):\n",
        "        \"\"\"Parses and loads the weights stored in 'weights_path'\"\"\"\n",
        "\n",
        "        # Open the weights file\n",
        "        with open(weights_path, \"rb\") as f:\n",
        "            header = np.fromfile(f, dtype=np.int32, count=5)  # First five are header values\n",
        "            self.header_info = header  # Needed to write header when saving weights\n",
        "            self.seen = header[3]  # number of images seen during training\n",
        "            weights = np.fromfile(f, dtype=np.float32)  # The rest are weights\n",
        "\n",
        "        ptr = 0\n",
        "        conv_layer = None\n",
        "        # refer to https://github.com/eriklindernoren/PyTorch-YOLOv3/blob/master/models.py\n",
        "        for i, module in enumerate(self.modules()):\n",
        "            if isinstance(module, nn.Conv2d):\n",
        "                conv_layer = module\n",
        "            if isinstance(module, nn.BatchNorm2d):\n",
        "                bn_layer = module\n",
        "                num_b = bn_layer.bias.numel()  # Number of biases\n",
        "\n",
        "                # Bias\n",
        "                bn_b = torch.from_numpy(weights[ptr: ptr + num_b]).view_as(bn_layer.bias)\n",
        "                bn_layer.bias.data.copy_(bn_b)\n",
        "                ptr += num_b\n",
        "\n",
        "                # Weight\n",
        "                bn_w = torch.from_numpy(weights[ptr: ptr + num_b]).view_as(bn_layer.weight)\n",
        "                bn_layer.weight.data.copy_(bn_w)\n",
        "                ptr += num_b\n",
        "\n",
        "                # Running Mean\n",
        "                bn_rm = torch.from_numpy(weights[ptr: ptr + num_b]).view_as(bn_layer.running_mean)\n",
        "                bn_layer.running_mean.data.copy_(bn_rm)\n",
        "                ptr += num_b\n",
        "\n",
        "                # Running Var\n",
        "                bn_rv = torch.from_numpy(weights[ptr: ptr + num_b]).view_as(bn_layer.running_var)\n",
        "                bn_layer.running_var.data.copy_(bn_rv)\n",
        "                ptr += num_b\n",
        "            else:\n",
        "                continue\n",
        "            # Load conv. weights\n",
        "            num_w = conv_layer.weight.numel()\n",
        "            conv_w = torch.from_numpy(weights[ptr: ptr + num_w]).view_as(conv_layer.weight)\n",
        "            conv_layer.weight.data.copy_(conv_w)\n",
        "            ptr += num_w\n",
        "\n",
        "\n",
        "# https://github.com/ultralytics/yolov5/blob/850970e081687df6427898948a27df37ab4de5d3/models/common.py#L139\n",
        "class SPPNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.conv1 = nn.Sequential(\n",
        "                        nn.Conv2d(1024, 512, 1, stride=1, padding=0, bias=False),\n",
        "                        nn.BatchNorm2d(512),\n",
        "                        Mish(),\n",
        "        )\n",
        "        self.conv2 = nn.Sequential(\n",
        "            nn.Conv2d(2048, 2048, 1, stride=1, padding=0, bias=False),\n",
        "            nn.BatchNorm2d(2048),\n",
        "            Mish(),\n",
        "        )\n",
        "\n",
        "        self.maxpool5 = nn.MaxPool2d(kernel_size=5, stride=1, padding=5//2)\n",
        "        self.maxpool9 = nn.MaxPool2d(kernel_size=9, stride=1, padding=9//2)\n",
        "        self.maxpool13 = nn.MaxPool2d(kernel_size=13, stride=1, padding=13//2)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv1(x)   # torch.Size([1, 512, 16, 16])\n",
        "        maxpool5 = self.maxpool5(x)\n",
        "        maxpool9 = self.maxpool9(x)\n",
        "        maxpool13 = self.maxpool13(x)\n",
        "        x = torch.cat([x, maxpool5, maxpool9, maxpool13], dim=1)\n",
        "        x = self.conv2(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "class PANet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(PANet, self).__init__()\n",
        "\n",
        "        self.p52d5 = nn.Sequential(nn.Conv2d(2048, 512, 1, stride=1, padding=0, bias=False),\n",
        "                                   nn.BatchNorm2d(512),\n",
        "                                   Mish(),\n",
        "                                   nn.Conv2d(512, 1024, 3, stride=1, padding=1, bias=False),\n",
        "                                   nn.BatchNorm2d(1024),\n",
        "                                   Mish(),\n",
        "                                   nn.Conv2d(1024, 512, 1, stride=1, padding=0, bias=False),\n",
        "                                   nn.BatchNorm2d(512),\n",
        "                                   Mish(),\n",
        "                                   )\n",
        "\n",
        "        self.p42p4_ = nn.Sequential(nn.Conv2d(512, 256, 1, stride=1, padding=0, bias=False),\n",
        "                                    nn.BatchNorm2d(256),\n",
        "                                    Mish(),\n",
        "                                    )\n",
        "\n",
        "        self.p32p3_ = nn.Sequential(nn.Conv2d(256, 128, 1, stride=1, padding=0, bias=False),\n",
        "                                    nn.BatchNorm2d(128),\n",
        "                                    Mish(),\n",
        "                                    )\n",
        "\n",
        "        self.d5_p4_2d4 = nn.Sequential(nn.Conv2d(512, 256, 1, stride=1, padding=0, bias=False),\n",
        "                                       nn.BatchNorm2d(256),\n",
        "                                       Mish(),\n",
        "                                       nn.Conv2d(256, 512, 3, stride=1, padding=1, bias=False),\n",
        "                                       nn.BatchNorm2d(512),\n",
        "                                       Mish(),\n",
        "                                       nn.Conv2d(512, 256, 1, stride=1, padding=0, bias=False),\n",
        "                                       nn.BatchNorm2d(256),\n",
        "                                       Mish(),\n",
        "                                       nn.Conv2d(256, 512, 3, stride=1, padding=1, bias=False),\n",
        "                                       nn.BatchNorm2d(512),\n",
        "                                       Mish(),\n",
        "                                       nn.Conv2d(512, 256, 1, stride=1, padding=0, bias=False),\n",
        "                                       nn.BatchNorm2d(256),\n",
        "                                       Mish(),\n",
        "                                       )\n",
        "\n",
        "        self.d4_p3_2d3 = nn.Sequential(nn.Conv2d(256, 128, 1, stride=1, padding=0, bias=False),\n",
        "                                       nn.BatchNorm2d(128),\n",
        "                                       Mish(),\n",
        "                                       nn.Conv2d(128, 256, 3, stride=1, padding=1, bias=False),\n",
        "                                       nn.BatchNorm2d(256),\n",
        "                                       Mish(),\n",
        "                                       nn.Conv2d(256, 128, 1, stride=1, padding=0, bias=False),\n",
        "                                       nn.BatchNorm2d(128),\n",
        "                                       Mish(),\n",
        "                                       nn.Conv2d(128, 256, 3, stride=1, padding=1, bias=False),\n",
        "                                       nn.BatchNorm2d(256),\n",
        "                                       Mish(),\n",
        "                                       nn.Conv2d(256, 128, 1, stride=1, padding=0, bias=False),\n",
        "                                       nn.BatchNorm2d(128),\n",
        "                                       Mish(),\n",
        "                                       )\n",
        "\n",
        "        self.d52d5_ = nn.Sequential(nn.Conv2d(512, 256, 1, stride=1, padding=0, bias=False),\n",
        "                                    nn.BatchNorm2d(256),\n",
        "                                    Mish(),\n",
        "                                    nn.Upsample(scale_factor=2)\n",
        "                                    )\n",
        "\n",
        "        self.d42d4_ = nn.Sequential(nn.Conv2d(256, 128, 1, stride=1, padding=0, bias=False),\n",
        "                                    nn.BatchNorm2d(128),\n",
        "                                    Mish(),\n",
        "                                    nn.Upsample(scale_factor=2)\n",
        "                                    )\n",
        "\n",
        "        self.u32u3_ = nn.Sequential(nn.Conv2d(128, 256, 3, stride=2, padding=1, bias=False),\n",
        "                                    nn.BatchNorm2d(256),\n",
        "                                    Mish())\n",
        "\n",
        "        self.u42u4_ = nn.Sequential(nn.Conv2d(256, 512, 3, stride=2, padding=1, bias=False),\n",
        "                                    nn.BatchNorm2d(512),\n",
        "                                    Mish())\n",
        "\n",
        "        self.d4u3_2u4 = nn.Sequential(nn.Conv2d(512, 256, 1, stride=1, padding=0, bias=False),\n",
        "                                      nn.BatchNorm2d(256),\n",
        "                                      Mish(),\n",
        "\n",
        "                                      nn.Conv2d(256, 512, 3, stride=1, padding=1, bias=False),\n",
        "                                      nn.BatchNorm2d(512),\n",
        "                                      Mish(),\n",
        "\n",
        "                                      nn.Conv2d(512, 256, 1, stride=1, padding=0, bias=False),\n",
        "                                      nn.BatchNorm2d(256),\n",
        "                                      Mish(),\n",
        "\n",
        "                                      nn.Conv2d(256, 512, 3, stride=1, padding=1, bias=False),\n",
        "                                      nn.BatchNorm2d(512),\n",
        "                                      Mish(),\n",
        "\n",
        "                                      nn.Conv2d(512, 256, 1, stride=1, padding=0, bias=False),\n",
        "                                      nn.BatchNorm2d(256),\n",
        "                                      Mish(),\n",
        "                                      )\n",
        "\n",
        "        self.d5u4_2u5 = nn.Sequential(nn.Conv2d(1024, 512, 1, stride=1, padding=0, bias=False),\n",
        "                                      nn.BatchNorm2d(512),\n",
        "                                      Mish(),\n",
        "\n",
        "                                      nn.Conv2d(512, 1024, 3, stride=1, padding=1, bias=False),\n",
        "                                      nn.BatchNorm2d(1024),\n",
        "                                      Mish(),\n",
        "\n",
        "                                      nn.Conv2d(1024, 512, 1, stride=1, padding=0, bias=False),\n",
        "                                      nn.BatchNorm2d(512),\n",
        "                                      Mish(),\n",
        "\n",
        "                                      nn.Conv2d(512, 1024, 3, stride=1, padding=1, bias=False),\n",
        "                                      nn.BatchNorm2d(1024),\n",
        "                                      Mish(),\n",
        "\n",
        "                                      nn.Conv2d(1024, 512, 1, stride=1, padding=0, bias=False),\n",
        "                                      nn.BatchNorm2d(512),\n",
        "                                      Mish(),\n",
        "                                      )\n",
        "\n",
        "    def forward(self, P5, P4, P3):\n",
        "        D5 = self.p52d5(P5)    # [B, 512, 13, 13]\n",
        "        D5_ = self.d52d5_(D5)  # [B, 256, 26, 26]\n",
        "        P4_ = self.p42p4_(P4)  # [B, 256, 26, 26]\n",
        "        D4 = self.d5_p4_2d4(torch.cat([D5_, P4_], dim=1))   # [B, 256, 26, 26]\n",
        "        D4_ = self.d42d4_(D4)                               # [B, 128, 52, 52]\n",
        "        P3_ = self.p32p3_(P3)                               # [B, 128, 52, 52]\n",
        "        D3 = self.d4_p3_2d3(torch.cat([D4_, P3_], dim=1))   # [B, 128, 52, 52]\n",
        "\n",
        "        U3 = D3                                             # [B, 128, 52, 52]   V\n",
        "        U3_ = self.u32u3_(U3)\n",
        "        U4 = self.d4u3_2u4(torch.cat([D4, U3_], dim=1))     # [B, 256, 26, 26]   V\n",
        "        U4_ = self.u42u4_(U4)                               # [B, 512, 13, 13]\n",
        "        U5 = self.d5u4_2u5(torch.cat([D5, U4_], dim=1))     # [B, 512, 13, 13]   V\n",
        "\n",
        "        return [U5, U4, U3]\n",
        "\n",
        "\n",
        "class YOLOv4(nn.Module):\n",
        "    def __init__(self, backbone, num_classes=20):\n",
        "        super(YOLOv4, self).__init__()\n",
        "        self.num_classes = num_classes\n",
        "        self.backbone = backbone\n",
        "        self.SPP = SPPNet()\n",
        "        self.PANet = PANet()\n",
        "\n",
        "        self.pred_s = nn.Sequential(nn.Conv2d(128, 256, 3, stride=1, padding=1, bias=False),\n",
        "                                    nn.BatchNorm2d(256),\n",
        "                                    Mish(),\n",
        "                                    nn.Conv2d(256, 3 * (1 + 4 + self.num_classes), 1, stride=1, padding=0))\n",
        "\n",
        "        self.pred_m = nn.Sequential(nn.Conv2d(256, 512, 3, stride=1, padding=1, bias=False),\n",
        "                                    nn.BatchNorm2d(512),\n",
        "                                    Mish(),\n",
        "                                    nn.Conv2d(512, 3 * (1 + 4 + self.num_classes), 1, stride=1, padding=0))\n",
        "\n",
        "        self.pred_l = nn.Sequential(nn.Conv2d(512, 1024, 3, stride=1, padding=1, bias=False),\n",
        "                                    nn.BatchNorm2d(1024),\n",
        "                                    Mish(),\n",
        "                                    nn.Conv2d(1024, 3 * (1 + 4 + self.num_classes), 1, stride=1, padding=0))\n",
        "\n",
        "        print(\"num_params : \", self.count_parameters())\n",
        "\n",
        "    def count_parameters(self):\n",
        "        return sum(p.numel() for p in self.parameters() if p.requires_grad)\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "        P3 = x = self.backbone.features1(x)  # [B, 256, 52, 52]\n",
        "        P4 = x = self.backbone.features2(x)  # [B, 512, 26, 26]\n",
        "        P5 = x = self.backbone.features3(x)  # [B, 1024, 13, 13]\n",
        "\n",
        "        P5 = self.SPP(P5)\n",
        "        U5, U4, U3 = self.PANet(P5, P4, P3)\n",
        "\n",
        "        p_l = self.pred_l(U5).reshape(x.shape[0], 3, 20 + 5, 13, 13).permute(0, 1, 3, 4, 2) # B, 13, 13, 255\n",
        "        p_m = self.pred_m(U4).reshape(x.shape[0], 3, 20 + 5, 26, 26).permute(0, 1, 3, 4, 2)  # B, 26, 26, 255\n",
        "        p_s = self.pred_s(U3).reshape(x.shape[0], 3, 20 + 5, 52, 52).permute(0, 1, 3, 4, 2)  # B, 52, 52, 255\n",
        "\n",
        "        return [p_l, p_m, p_s]\n",
        "\n",
        "\".reshape(x.shape[0], 3, 20 + 5, x.shape[2], x.shape[3]).permute(0, 1, 3, 4, 2)\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "nbhEvjitEdDn",
        "outputId": "636431fd-6998-4f3b-c064-1013904ba577"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'.reshape(x.shape[0], 3, 20 + 5, x.shape[2], x.shape[3]).permute(0, 1, 3, 4, 2)'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}